# cudaformer

Implement a full (encoder + decoder for the anki spanish-english translation dataset) transformer algorithm on a nvidia tesla m60 gpu. 


TO-DO: 

()Fix multi-headed attention 

()Make embedding -> positional encoding not suck so much 

()Implement FNN that doesn't suck 

()Connect the encoder and decoder more 

